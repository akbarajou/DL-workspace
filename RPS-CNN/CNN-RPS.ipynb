{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rock-Paper-Scissors Classification with Convolutional Neural Networks (CNN)**\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will build a Convolutional Neural Network (CNN) to classify images of hand gestures: Rock, Paper, and Scissors. The process will include:\n",
    "\n",
    "1. **Importing Libraries**\n",
    "2. **Data Loading and Preparation**\n",
    "3. **Model Building**\n",
    "4. **Model Training**\n",
    "5. **Model Evaluation**\n",
    "6. **Making Predictions on New Images**\n",
    "\n",
    "We will use TensorFlow and Keras for building the model and work through each step with detailed explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importing Necessary Libraries**\n",
    "\n",
    "We start by importing essential libraries:\n",
    "\n",
    "- **TensorFlow**: Main library for building and training the CNN.\n",
    "- **TensorFlow Datasets**: For loading the Rock-Paper-Scissors dataset.\n",
    "- **NumPy**: For numerical operations.\n",
    "- **Matplotlib.pyplot**: For data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Loading and Preparing the Dataset**\n",
    "\n",
    "We will load the Rock-Paper-Scissors dataset from TensorFlow Datasets and preprocess it by:\n",
    "\n",
    "- **Resizing Images**: Standardizing image sizes.\n",
    "- **Normalizing Pixel Values**: Scaling pixel values to the range [0, 1].\n",
    "- **Data Augmentation**: Enhancing the dataset with transformed images to improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'rock_paper_scissors',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# Define image size and batch size\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to the datasets\n",
    "train_ds = train_ds.map(preprocess).batch(BATCH_SIZE)\n",
    "test_ds = test_ds.map(preprocess).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Visualization**\n",
    "\n",
    "Let's visualize a few samples from the training dataset to understand what the images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ds_info.features['label'].names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Building the CNN Model**\n",
    "\n",
    "We will build a Sequential CNN model consisting of:\n",
    "\n",
    "- **Convolutional Layers**: To extract features from images.\n",
    "- **Pooling Layers**: To reduce spatial dimensions.\n",
    "- **Flatten Layer**: To convert the 2D feature maps into 1D feature vectors.\n",
    "- **Dense Layers**: For classification based on extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=IMG_SIZE + (3,)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: Rock, Paper, Scissors\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compiling the Model**\n",
    "\n",
    "We compile the model using:\n",
    "\n",
    "- **Loss Function**: `sparse_categorical_crossentropy` for multi-class classification.\n",
    "- **Optimizer**: `adam` optimizer for efficient training.\n",
    "- **Metrics**: `accuracy` to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Training the Model**\n",
    "\n",
    "We train the model using the training dataset for a certain number of epochs.\n",
    "\n",
    "- **Epochs**: Number of times the model will cycle through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Evaluating the Model**\n",
    "\n",
    "After training, we evaluate the model on the test dataset to check its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Training Results**\n",
    "\n",
    "We plot the training and validation accuracy and loss to visualize the model's performance over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **9. Making Predictions on New Images**\n",
    "\n",
    "We can use the trained model to predict the class of new images.\n",
    "\n",
    "- **Load and Preprocess the Image**: Resize and normalize the image.\n",
    "- **Predict**: Use `model.predict` to get the prediction probabilities.\n",
    "- **Interpret the Result**: Find the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    image_array = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
    "    image_array = tf.expand_dims(image_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(image_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = np.max(predictions[0])\n",
    "\n",
    "    plt.imshow(image_array[0])\n",
    "    plt.title(f'Prediction: {predicted_class} ({confidence * 100:.2f}%)')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the Model with a New Image**\n",
    "\n",
    "Let's test the model with a new image of a hand gesture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path to your image\n",
    "image_path = 'scissor.jpg'\n",
    "predict_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
